---
title: "Streaming"
icon: "comments"
---

This API provides streaming speech-to-text transcriptions using WebSockets.

<Note>
Endpoint:<br/>`wss://api.sully.ai/v1/audio/transcriptions/stream?account_id=1234567890&api_token=1234567890&sample_rate=16000&language=en`
</Note>

## Headers

<ParamField query="X-API-KEY" type="string">
    The API key to use for authentication. Required if `X-API-TOKEN` is not provided.
</ParamField>

<ParamField query="X-API-TOKEN" type="string">
    The API token to use for authentication. Required if `X-API-KEY` is not provided.
</ParamField>

<ParamField query="X-ACCOUNT-ID" type="string">
    The account ID to use for authentication.
</ParamField>

## Query parameters

<ParamField query="language" type="string" default="en">
    The language of your submitted audio. See our [Supported Languages](/api-reference/audio-transcriptions/languages) documentation for a complete list of language options.
</ParamField>

<ParamField query="sample_rate" type="string">
    The sample rate of your submitted audio.
</ParamField>

<ParamField query="encoding" type="string">
      Specifies the encoding format of the audio being sent.
      
      <b>Important:</b> This parameter is <b>required</b> when transmitting raw, unstructured audio packets without headers. 
      If the audio data is encapsulated within a container format, this parameter should be omitted.

      <b>Supported formats:</b>
      <ul>
        <li><code>linear16</code>: 16-bit, little-endian PCM audio</li>
        <li><code>flac</code>: Free Lossless Audio Codec (FLAC)</li>
        <li><code>mulaw</code>: Mu-law encoded WAV</li>
        <li><code>amr-nb</code>: Adaptive Multi-Rate, narrowband</li>
        <li><code>amr-wb</code>: Adaptive Multi-Rate, wideband</li>
        <li><code>opus</code>: Ogg Opus codec</li>
        <li><code>speex</code>: Speex codec</li>
        <li><code>g729</code>: G729 codec (usable with raw or containerized audio)</li>
      </ul>
</ParamField>

<ParamField query="account_id" type="string">
    The account ID to use for authentication. Required if `X-ACCOUNT-ID` is not provided.
</ParamField>

<ParamField query="api_token" type="string">
    A temporary authentication token. Required if `X-API-KEY` is not provided.
</ParamField>

# When to use

The Speech-to-Text Websockets API is designed to generate text from partial audio input. It's well-suited for scenarios where the input audio is being streamed or generated in chunks.

# Protocol

The WebSocket API uses a bidirectional protocol that encodes all messages as JSON objects.

## Connection Status Messages

Upon successful connection, the server sends a status message:

```json
{
  "status": "connected",
}
```

When the connection closes:

```json
{
  "status": "disconnected",
}
```

<Note>
  **Important:** Wait for the "status": "connected" message before sending audio data. This ensures the server is ready to process your stream.
</Note>

# Streaming input audio

The client can send messages with audio input to the server. The messages can contain the following fields:
```json
{
  "audio": "Y3VyaW91cyBtaW5kcyB0aGluayBhbGlrZSA6KQ=="
}
```

<ParamField body="audio" type="string" required>
    A generated partial audio chunk encoded as a base64 string.
</ParamField>

<Note>
  **Browser MediaRecorder Notice:** When using Chrome's MediaRecorder API, the first audio chunk contains critical header information. Always send this first chunk for proper audio processing. Failing to include header information may result in transcription errors or complete failure.
</Note>

## Streaming output audio

The server will always respond with a message containing the following fields:

```json Response message
{
  "type": "transcript",
  "audio_start": 0,
  "audio_end": 3.2,
  "duration": 3.2,
  "text": "Hello, world",
  "isFinal": false, 
  "is_final": false,
  "words": [
    {
      "word": "Hello",
      "start": 0.2,
      "end": 0.7,
      "confidence": 0.9856743,
      "punctuated_word": "Hello,"
    },
    {
      "word": "world",
      "start": 0.9,
      "end": 1.2,
      "confidence": 0.9978341,
      "punctuated_word": "world"
    }
  ],
  "timestamp": "2023-08-15T14:32:07.123Z"
}
```

<ResponseField name="type" type="string">
  The type of response, will be "transcript" for transcription results.
</ResponseField>

<ResponseField name="audio_start" type="number">
  Start time of the audio segment in seconds.
</ResponseField>

<ResponseField name="audio_end" type="number">
  End time of the audio segment in seconds.
</ResponseField>

<ResponseField name="duration" type="number">
  Duration of the audio segment in seconds.
</ResponseField>

<ResponseField name="text" type="string">
  The processed text sequence.
</ResponseField>

<ResponseField name="isFinal" type="boolean" deprecated>
  Indicates if the generation is complete. <b>Deprecated:</b> Use <code>is_final</code> instead.
</ResponseField>

<ResponseField name="is_final" type="boolean">
  Indicates if the generation is complete.
</ResponseField>

<ResponseField name="words" type="array">
  Array of word objects with text content and timing information:
  <ul>
    <li><code>word</code>: The raw word as recognized</li>
    <li><code>start</code>: Start time of the word in seconds</li>
    <li><code>end</code>: End time of the word in seconds</li>
    <li><code>confidence</code>: Confidence score between 0-1 for the word recognition</li>
    <li><code>punctuated_word</code>: The word with proper capitalization and punctuation</li>
  </ul>
</ResponseField>

<ResponseField name="timestamp" type="string">
  ISO-formatted timestamp when the response was generated.
</ResponseField>
